

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>A dynamically-generated robots.txt: will search engine bots recognize themselves? - Arun Kumar</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Arun Kumar">
<meta property="og:title" content="A dynamically-generated robots.txt: will search engine bots recognize themselves?">


  <link rel="canonical" href="http://localhost:4000/posts/2014/05/robots-txt/">
  <meta property="og:url" content="http://localhost:4000/posts/2014/05/robots-txt/">



  <meta property="og:description" content="I built a script that dynamically generates a robots.txt file for search engine bots, who download the file when they seek direction on what parts of a website they are allowed to index. By default, it directs all bots to stay away from the entire site, but then presents an exception: only the bot that requests the robots.txt file is allowed full reign over the site.">



  <meta name="twitter:site" content="@staeiou">
  <meta name="twitter:title" content="A dynamically-generated robots.txt: will search engine bots recognize themselves?">
  <meta name="twitter:description" content="I built a script that dynamically generates a robots.txt file for search engine bots, who download the file when they seek direction on what parts of a website they are allowed to index. By default, it directs all bots to stay away from the entire site, but then presents an exception: only the bot that requests the robots.txt file is allowed full reign over the site.">
  <meta name="twitter:url" content="http://localhost:4000/posts/2014/05/robots-txt/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="http://localhost:4000/images/site-logo.png">
    
  

  
    <meta name="twitter:creator" content="@stuart">
  



  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2014-05-13T18:37:02-07:00">






  <meta name="google-site-verification" content="3hdu0GcCfjZ6WbPpApjcdcEGjsCPDcDn1QLtBm-DRBg" />






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Kumar Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">

<script type="application/ld+json"> 
{ 
"@context": "http://schema.org",
"@type": "Person",
"name": "R. Stuart Geiger",
"email": "mailto:stuart@stuartgeiger.com",
"image": "http://stuartgeiger.com/images/oban3.jpg",
"jobTitle": "Ethnographer",
"name": "R. Stuart Geiger",
"affiliation": "University of California, Berkeley",
"alumniOf": "University of California, Berkeley",
"birthPlace": "Nacogdoches County, TX",
"gender": "male",
"honorificSuffix": "PhD",
"nationality": "United States",
"url": "http://www.stuartgeiger.com",
"sameAs" : [
"http://twitter.com/staeiou",
"http://github.com/staeiou",
"https://orcid.org/0000-0001-7215-0532"] 
} </script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Arun Kumar</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/articles/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talks/">Talks</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/expressions/">Expressions</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/contact/">Contact</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    

    <script type="application/ld+json">
    {
	"@context": "http://schema.org/",
	"@type": "CreativeWork",
	"author": "R. Stuart Geiger",
        "name": "A dynamically-generated robots.txt: will search engine bots recognize themselves?",
	"datePublished": "2014-05-13 18:37:02 -0700",
	"description": "I built a script that dynamically generates a robots.txt file for search engine bots, who download the file when they seek direction on what parts of a website they are allowed to index. By default, it directs all bots to stay away from the entire site, but then presents an exception: only the bot that requests the robots.txt file is allowed full reign over the site."
    }
    </script>




<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div>

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/arun.jpg" class="author__avatar" alt="Arun Kumar">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Arun Kumar</h3>
    <p class="author__bio">Robotics and Artificial Intelligence Researcher | Project Associate at the <a style='color: black;' href='http://rbccps.org'>Robert Bosch Centere for Cyber Physical Systems, IISc</a></p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Bangalore, India</li>
      
      
      
      
      
      
        <li><a href="https://twitter.com/staeiou"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/ioarun"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=0AvWi3wAAAAJ&hl=en"><i class="fa fa-fw fa-chain" aria-hidden="true"></i> Google Scholar</a></li>
      
      
        <li><a href="http://orcid.org/0000-0001-7215-0532"><i class="fa fa-fw fa-chain" aria-hidden="true"></i> ORCID</a></li>
      
      
        <li><a href="https://en.wikipedia.org/wiki/User:staeiou"><i class="fa fa-fw fa-chain" aria-hidden="true"></i> Wikipedia</a></li>
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="A dynamically-generated robots.txt: will search engine bots recognize themselves?">
    <meta itemprop="description" content="I built a script that dynamically generates a robots.txt file for search engine bots, who download the file when they seek direction on what parts of a website they are allowed to index. By default, it directs all bots to stay away from the entire site, but then presents an exception: only the bot that requests the robots.txt file is allowed full reign over the site.">
    <meta itemprop="datePublished" content="May 13, 2014">
    
    


    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">A dynamically-generated robots.txt: will search engine bots recognize themselves?
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  7 minute read
	
</p>
          
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-05-13T18:37:02-07:00">May 13, 2014</time></p>
        
        </header>
      

      <section class="page__content" itemprop="text">
        <p>In short, I built a script that dynamically generates a robots.txt file for search engine bots, who download the file when they seek direction on what parts of a website they are allowed to index. By default, it directs all bots to stay away from the entire site, but then presents an exception: only the bot that requests the robots.txt file is allowed full reign over the site. If Google’s bot downloads the robots.txt file, it will see that only Google’s bot gets to index the entire site. If Yahoo’s bot downloads the robots.txt file, it will see that only Yahoo’s bot gets to index the entire site. Of course, this is assuming that bots identify themselves to my server in a way that they recognize when it is reflected back to them.</p>

<!--more-->

<p><span style="color: #292f33;">What is a robots.txt file? Most websites have one of these very simple file called “robots.txt” on the main directory of their server. The robots.txt file has been around for almost two decades, and it is now a standardized way of communicating what pages search engine bots (or crawlers) should and should not visit. Crawlers are supposed to request and download a robots.txt file from any website they visit, and then obey the directives mentioned in such a file. Of course, there is nothing which prevents a crawler from still crawling pages which are forbidden in a robots.txt file, but most major search engine bots behave themselves. </span></p>

<p><span style="color: #292f33;">In many ways, robots.txt files stand out as a legacy from a much earlier time. When was the last time you wrote something for public distribution in a .txt file, anyway? In an age of server-side scripting and content management systems, robots.txt is also one the few public-facing files a systems administrator will actually edit and maintain by hand, manually adding and removing entries in a text editor. A robots.txt file has no changelog in it, but its revision history would be a partial chronicle of a systems administrator’s interactions with how their website is represented by various search engines.</span><span style="color: #292f33;">You can specify different directives for different bots by specifying a user agent, and well-behaved bots are supposed to look for their own user agents in a robots.txt file and follow the instructions left for them. </span>As for my own, I’m sad to report that I simply let all bots through wherever they roam, as I use a sitemap.tar.gz file which a WordPress plugin generates for me on a regular basis and submits to the major search engines. So my robots.txt file just looks like this:</p>

<pre><span style="color: #000000;">User-agent: *
</span>Allow: /</pre>

<p><span style="color: #292f33;">An interesting thing about contemporary web servers is that file formats no longer really matter as much as they used to. In fact, files don’t even have to exist as we they are typically represented in URLs. When your browser requests the page http://stuartgeiger.com/wordpress/2014/05/robots-txt, there is a directory called “wordpress” on my server, but everything after that is a fiction. There is no directory called 2014, no a subdirectory called 05, and no file called robots-txt that existed on the server before or after you downloaded it. Rather, when WordPress receives a request to download this non-existent file, it intercepts it and interprets it as a request to dynamically generate a new HTML page on the fly. WordPress queries a database for the content of the post, inserts that into a theme, and then has the server send you that HTML page — with linked images, stylesheets, and Javascript files, which often do actually exist as files on a server. The server probably stores the dynamically-generated HTML page in its memory, and sometimes there is caching to pre-generate these pages to make things faster, but other than that, the only time an HTML file of this page ever exists in any persistent form is if you save it to your hard drive. </span></p>

<p><span style="color: #292f33;">Yet robots.txt lives on, doing its job well. It doesn’t need any fancy server-side scripting; it does just fine on its own. Still, I kept thinking about what it would be like to have a script dynamically generate a robots.txt file on the fly whenever it is requested. Given that the only time a robots.txt file is usually downloaded is when an automated software agent requests it, there is something strangely poetic about an algorithmically-generated robots.txt file. It is something that would, for the most part, only ever really exist in the fleeting interaction between two automated routines. So of course I had to build one.</span></p>

<p>The code required to implement this is trivial. First, I needed to modify how my web server interprets requests, so that whenever a request was made to robots.txt, the server would execute a script called robots.php and send the client the output as robots.txt. Modify the .htaccess file to add:</p>

<pre><span style="color: #000000;">RewriteEngine On
RewriteBase /
RewriteRule ^robots.txt$ /robots.php</span></pre>

<p>Next, the PHP script itself:</p>

<pre>&lt;?php
header('Content-Type:text/plain');
echo "User-agent: *" . "\r\n";
echo "Allow: /" . "\r\n";
?&gt;
</pre>

<p>Then I realized that this was all a little impersonal, and I could do better since I’m scripting. With PHP, I can easily query the user-agent of the client which is requesting the file, the identifier it sends to the web server. Normally, user agents define the browser that is requesting the page, but bots are supposed to have an identifiable user-agent like “Googlebot” or “Twitterbot” so that you can know them when they come to visit. Instead of granting access to every user agent with the asterisk, I made it so that the user agent of the requesting client is the only one that is directed to have full access.</p>

<pre>&lt;?php
header('Content-Type:text/plain');
echo "User-agent:" . $_SERVER['HTTP_USER_AGENT'] . "\r\n";
echo "Allow: /" . "\r\n";
?&gt;</pre>

<p>After making sure this worked, I realized that I needed to go out there a little more. If the bots didn’t recognize themselves, then by default, they would still be allowed to crawl the site anyway. robots.txt works on a principle of allow by default. So I needed to add a few more lines which made it so that the robots.txt file the bot downloaded would direct all <strong>other</strong> bots to <strong>not</strong> crawl the site, but give full reign to bots with the user agent it sent the server.</p>

<pre>&lt;?php
 header('Content-Type:text/plain');
 echo "User-agent: *" . "\r\n";
 echo "Disallow: /" . "\r\n";
 echo "User-agent:" . $_SERVER['HTTP_USER_AGENT'] . "\r\n";
 echo "Allow: /" . "\r\n";
 ?&gt;</pre>

<p>This is what you get if you download it in Chrome:</p>

<pre>User-agent: *
Disallow: /
User-agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.131 Safari/537.36 
Allow: /</pre>

<p>The restrictive version is now live, up at <a href="http://www.stuartgeiger.com/robots.txt">http://www.stuartgeiger.com/robots.txt</a>. I’ve also put it up <a href="https://github.com/staeiou/robots.txt.php">on github</a>, because apparently that’s what cool kids do. I’m looking forward to seeing what will happen. Google’s webmaster tools will notify me if its crawlers can’t index my site, for whatever reason, and I’m curious if Google’s bots will identify themselves to my servers in a way that they will recognize.</p>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#algorithms" class="page__taxonomy-item" rel="tag">algorithms</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#bots" class="page__taxonomy-item" rel="tag">bots</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#communication" class="page__taxonomy-item" rel="tag">communication</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#discourse" class="page__taxonomy-item" rel="tag">discourse</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#infrastructure" class="page__taxonomy-item" rel="tag">infrastructure</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#internet" class="page__taxonomy-item" rel="tag">internet</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#philosophy" class="page__taxonomy-item" rel="tag">philosophy</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#technology" class="page__taxonomy-item" rel="tag">technology</a>
    
    </span>
  </p>




  






  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/categories/#blog-posts" class="page__taxonomy-item" rel="tag">Blog Posts</a>
    
    </span>
  </p>


      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/posts/2014/05/robots-txt/" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/posts/2014/05/robots-txt/" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http://localhost:4000/posts/2014/05/robots-txt/" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/posts/2014/05/robots-txt/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/posts/2014/01/bots-bespoke-code-and-the-materiality-of-software-platforms/" class="pagination--pager" title="Bots, bespoke code, and the materiality of software platforms
">Previous</a>
    
    
      <a href="http://localhost:4000/posts/2015/01/register-to-the-trace-ethnography-workshop-at-the-2015-iconference/" class="pagination--pager" title="Come to the Trace Ethnography workshop at the 2015 iConference!
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      
        <h4 class="page__related-title">You May Also Enjoy</h4>
      
      <div class="grid__wrapper">
        
          





<div class="grid__item">
  <article class="archive__item">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/10/best-practices-team-challenges" rel="permalink">Best Practices Team Challenges
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  11 minute read
	
</p>
    
    
    
      <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-10-31T00:00:00-07:00">October 31, 2018</time></p>
    

    
    <p class="archive__item-excerpt" itemprop="description"><p>A summary of the first BIDS Best Practices lunch discussion, where we shared the challenges of doing research in groups.
<u><strong><a href="http://localhost:4000/posts/2018/10/best-practices-team-challenges" rel="permalink"> Read more</a></strong></u></p></p>
    

    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/04/so-you-want-to-start-a-data-science-institute" rel="permalink">So you want to start a data science institute? Achieving sustainability
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  14 minute read
	
</p>
    
    
    
      <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-04-19T00:00:00-07:00">April 19, 2018</time></p>
    

    
    <p class="archive__item-excerpt" itemprop="description"><p>A cross-post of a piece that synthesizes the experiences of many in academic data science institutes and research software engineering groups, focused on what is important in sustaining these cross-disciplinary efforts over time.
<u><strong><a href="http://localhost:4000/posts/2018/04/so-you-want-to-start-a-data-science-institute" rel="permalink"> Read more</a></strong></u></p></p>
    

    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/04/so-you-want-to-start-a-data-science-institute" rel="permalink">Research Software Engineers and Data Scientists: More in Common
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  6 minute read
	
</p>
    
    
    
      <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-04-19T00:00:00-07:00">April 19, 2018</time></p>
    

    
    <p class="archive__item-excerpt" itemprop="description"><p>A cross-post of a piece about defining the roles, scopes, and challenges of data scientists and research software engineers, in which we conclude we have more in common and that our differences come more from the context in which these terms and roles emerged.
<u><strong><a href="http://localhost:4000/posts/2018/04/so-you-want-to-start-a-data-science-institute" rel="permalink"> Read more</a></strong></u></p></p>
    

    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2018/04/keeping-computation-open-to-interpretation" rel="permalink">Keeping computation open to interpetation: Ethnographers, step right in, please
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  17 minute read
	
</p>
    
    
    
      <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2018-04-16T00:00:00-07:00">April 16, 2018</time></p>
    

    
    <p class="archive__item-excerpt" itemprop="description"><p>A cross-post of a piece written with members of ITU Copenhagen’s ETHOSlab, based on a workshop we held about the role of interpretivist social science and humanistic approaches in computation.
<u><strong><a href="http://localhost:4000/posts/2018/04/keeping-computation-open-to-interpretation" rel="permalink"> Read more</a></strong></u></p></p>
    

    
    

  </article>
</div>

        
      </div>
    </div>
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/staeiou"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
      <li><a href="http://github.com/ioarun"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Arun Kumar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79273-2', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

